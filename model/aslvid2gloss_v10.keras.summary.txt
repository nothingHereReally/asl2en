model file ./aslvid2gloss_v10.2.keras
    result is overfitting, due to on training:
        Total params: 131,811,866 (502.82 MB)
        Trainable params: 43,937,288 (167.61 MB)
        Non-trainable params: 0 (0.00 B)
        Optimizer params: 87,874,578 (335.21 MB)
        Epoch 1/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10255s 1s/step - accuracy: 0.7814 - loss: 0.9775
        Epoch 2/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10128s 1s/step - accuracy: 0.8969 - loss: 0.4137
        Epoch 3/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10059s 1s/step - accuracy: 0.9374 - loss: 0.2319
        Epoch 4/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10276s 1s/step - accuracy: 0.9557 - loss: 0.1522
        Epoch 5/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10209s 1s/step - accuracy: 0.9677 - loss: 0.1138
    and yet on testing:
        ...
        1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 36ms/step
        INcorrect( should be wheelchair ) calculated be wet 33.26386642456055% ________ 63044
        current in progress idx 2877
        1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step
        INcorrect( should be whistle ) calculated be rather 48.86885452270508% ________ 63185
        correct 121 / 2878 = 4.204308547602502%

model file ./aslvid2gloss_v10.1.keras
    result is overfitting, due to on training:
        Total params: 131,811,866 (502.82 MB)
        Trainable params: 43,937,288 (167.61 MB)
        Non-trainable params: 0 (0.00 B)
        Optimizer params: 87,874,578 (335.21 MB)
        Epoch 1/2
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10240s 1s/step - accuracy: 0.4020 - loss: 3.6782
        Epoch 2/2
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10222s 1s/step - accuracy: 0.7064 - loss: 1.4489
    and yet testing see ./aslvid2gloss_v10.2.keras above

model file ./aslvid2gloss_v10.keras

batch train size( TRAIN_BATCH ): 2
TOTAL_GLOSS_UNIQ: 2000

Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ batch_vid (InputLayer)               │ (None, 3000, 150, 3)        │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ cnn2d_1 (Conv2D)                     │ (None, 2998, 148, 8)        │             224 │ <-- cnn2d (3,3) -- (1,1)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ mp2d_1 (MaxPooling2D)                │ (None, 1499, 74, 8)         │               0 │ <-- (2,2) -- (2,2)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ do_1 (Dropout)                       │ (None, 1499, 74, 8)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ cnn2d_2 (Conv2D)                     │ (None, 1497, 72, 16)        │           1,168 │ <-- cnn2d (3,3) -- (1,1)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ mp2d_2 (MaxPooling2D)                │ (None, 748, 36, 16)         │               0 │ <-- (2,2) -- (2,2)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ do_2 (Dropout)                       │ (None, 748, 36, 16)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ cnn2d_3 (Conv2D)                     │ (None, 746, 34, 24)         │           3,480 │ <-- cnn2d (3,3) -- (1,1)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ mp2d_3 (MaxPooling2D)                │ (None, 373, 17, 24)         │               0 │ <-- (2,2) -- (2,2)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ do_3 (Dropout)                       │ (None, 373, 17, 24)         │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ cnn2d_4 (Conv2D)                     │ (None, 371, 15, 24)         │           5,208 │ <-- cnn2d (3,3) -- (1,1)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ mp2d_4 (MaxPooling2D)                │ (None, 185, 7, 24)          │               0 │ <-- (2,2) -- (2,2)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ do_4 (Dropout)                       │ (None, 185, 7, 24)          │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ cnn2d_5 (Conv2D)                     │ (None, 183, 5, 24)          │           5,208 │ <-- cnn2d (3,3) -- (1,1)
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flat_1 (Flatten)                     │ (None, 21960)               │               0 │ <-- 183*5*24= 21960
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_class (Dense)                  │ (None, 2000)                │      43,922,000 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 43,937,288 (167.61 MB)
 Trainable params: 43,937,288 (167.61 MB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/2
7145/7145 ━━━━━━━━━━━━━━━━━━━━ 9960s 1s/step - accuracy: 0.0048 - loss: 7.5062
Epoch 2/2
7145/7145 ━━━━━━━━━━━━━━━━━━━━ 9185s 1s/step - accuracy: 0.3859 - loss: 3.5245
input size: (20*150, 150, 3) with getdata(isSimg=True) already in [0.0, 1.0] float32
optimizer: Adam(learning_rate=0.001),
loss: sparse_categorical_crossentropy,
metrics: ['accuracy']
epoch: 2
steps_per_epoch: TOTAL_TRAIN_FILE//TRAIN_BATCH








data_in= Input(
    shape=(QUANTITY_FRAME*IMG_SIZE, IMG_SIZE, 3),
    dtype=float32,
    name='batch_vid'
)



x= Conv2D(
    filters=8,
    kernel_size=(3,3),
    strides=(1,1),
    padding='valid',
    data_format='channels_last',
    activation=ReLU(negative_slope=0.0, max_value=256.0, threshold=0.0),
    name='cnn2d_1'
)(data_in)
x= MaxPooling2D(
    pool_size=(2,2),
    padding='valid',
    data_format='channels_last',
    name='mp2d_1'
)(x)
x= Dropout(
    rate=0.2,
    name='do_1'
)(x)
x= Conv2D(
    filters=16,
    kernel_size=(3,3),
    strides=(1,1),
    padding='valid',
    data_format='channels_last',
    activation=ReLU(negative_slope=0.0, max_value=256.0, threshold=0.0),
    name='cnn2d_2'
)(x)
x= MaxPooling2D(
    pool_size=(2,2),
    padding='valid',
    data_format='channels_last',
    name='mp2d_2'
)(x)
x= Dropout(
    rate=0.2,
    name='do_2'
)(x)
x= Conv2D(
    filters=24,
    kernel_size=(3,3),
    strides=(1,1),
    padding='valid',
    data_format='channels_last',
    activation=ReLU(negative_slope=0.0, max_value=256.0, threshold=0.0),
    name='cnn2d_3'
)(x)
x= MaxPooling2D(
    pool_size=(2,2),
    padding='valid',
    data_format='channels_last',
    name='mp2d_3'
)(x)
x= Dropout(
    rate=0.2,
    name='do_3'
)(x)
x= Conv2D(
    filters=24,
    kernel_size=(3,3),
    strides=(1,1),
    padding='valid',
    data_format='channels_last',
    activation=ReLU(negative_slope=0.0, max_value=256.0, threshold=0.0),
    name='cnn2d_4'
)(x)
x= MaxPooling2D(
    pool_size=(2,2),
    padding='valid',
    data_format='channels_last',
    name='mp2d_4'
)(x)
x= Dropout(
    rate=0.2,
    name='do_4'
)(x)
x= Conv2D(
    filters=24,
    kernel_size=(3,3),
    strides=(1,1),
    padding='valid',
    data_format='channels_last',
    activation=ReLU(negative_slope=0.0, max_value=256.0, threshold=0.0),
    name='cnn2d_5'
)(x)
# x= MaxPooling2D(
#     pool_size=(2,2),
#     padding='valid',
#     data_format='channels_last',
#     name='mp2d_5'
# )(x)
# x= Dropout(
#     rate=0.2,
#     name='do_5'
# )(x)
# x= Conv2D(
#     filters=24,
#     kernel_size=(3,3),
#     strides=(1,1),
#     padding='valid',
#     data_format='channels_last',
#     activation=ReLU(negative_slope=0.0, max_value=256.0, threshold=0.0),
#     name='cnn2d_6'
# )(x)
# x= MaxPooling2D(
#     pool_size=(2,2),
#     padding='valid',
#     data_format='channels_last',
#     name='mp2d_6'
# )(x)
# x= Dropout(
#     rate=0.2,
#     name='do_6'
# )(x)
# x= Conv2D(
#     filters=24,
#     kernel_size=(3,3),
#     strides=(1,1),
#     padding='valid',
#     data_format='channels_last',
#     activation=ReLU(negative_slope=0.0, max_value=256.0, threshold=0.0),
#     name='cnn2d_7'
# )(x)
# x= MaxPooling2D(
#     pool_size=(2,2),
#     padding='valid',
#     data_format='channels_last',
#     name='mp2d_7'
# )(x)
# x= Dropout(
#     rate=0.2,
#     name='do_7'
# )(x)


x= Flatten(
    name='flat_1'
)(x)
data_out= Dense(
    units=TOTAL_GLOSS_UNIQ,
    activation=softmax,
    name='batch_class'
)(x)








testing ./aslvid2gloss_v10.2.keras: src_asl2gloss/checks/test_asl_vid2gloss_model.py
_______________________________________________________
from os.path import exists
from keras.src.saving import load_model
from numpy import argmax, float32

from ..lmark_constant import IMG_SIZE, PROJ_ROOT, QUANTITY_FRAME, WLASL_VID_DIR, wlasl_READY


from ..lmark_essential_draw import getSkeletonFrames


def test(modelFile: str) -> None:
    if exists(modelFile):
        loadedModel= load_model(modelFile)
        correct: int= 0
        print(f"testing over {len(wlasl_READY['test'])} files, processing...")
        for cur, i in zip(range(len(wlasl_READY['test'])), wlasl_READY['test']):
            print(f"current in progress idx {cur}")
            out: list= loadedModel.predict(getSkeletonFrames(
                f"{WLASL_VID_DIR}{i['video_id']}.mp4",
                isSingleImg=True
            ).reshape((1, QUANTITY_FRAME*IMG_SIZE, IMG_SIZE, 3)).astype(float32)/255.0)
            out= out[0]
            if int(argmax(out, axis=-1))==int(i['gloss_id']):
                correct +=1
                print(f"correct( should be {wlasl_READY['label_id2gloss'][i['gloss_id']]} ) calculated be {wlasl_READY['label_id2gloss'][argmax(out, axis=-1)]} {out[argmax(out, axis=-1)]*100}%")
            else:
                print(f"INcorrect( should be {wlasl_READY['label_id2gloss'][i['gloss_id']]} ) calculated be {wlasl_READY['label_id2gloss'][argmax(out, axis=-1)]} {out[argmax(out, axis=-1)]*100}% ________ {i['video_id']}")
        print(f"correct {correct} / {len(wlasl_READY['test'])} = {correct/float(len(wlasl_READY['test']))*100}%")
    else:
        print(f"model file: {modelFile} does not exist")
    

if __name__=="__main__":
    test(f"{PROJ_ROOT}model/aslvid2gloss_v10.2.keras")

