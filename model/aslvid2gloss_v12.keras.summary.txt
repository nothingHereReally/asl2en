model file ./aslvid2gloss_v12.4.keras
    result is overfitting, due to on training:
        Total params: 94,185,002 (359.29 MB)
        Trainable params: 31,395,000 (119.76 MB)
        Non-trainable params: 0 (0.00 B)
        Optimizer params: 62,790,002 (239.52 MB)
        Epoch 1/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10288s 1s/step - accuracy: 0.7587 - loss: 1.1678
        Epoch 2/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10124s 1s/step - accuracy: 0.8770 - loss: 0.6540
        Epoch 3/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10059s 1s/step - accuracy: 0.9229 - loss: 0.4160
        Epoch 4/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10269s 1s/step - accuracy: 0.9496 - loss: 0.2620
        Epoch 5/5
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10196s 1s/step - accuracy: 0.9663 - loss: 0.1711
    and yet on testing:
        ...
        1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 39ms/step
        INcorrect( should be wheelchair ) calculated be repeat 13.794955611228943% ________ 63044
        current in progress idx 2877
        1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 38ms/step
        INcorrect( should be whistle ) calculated be oral 39.49519693851471% ________ 63185
        correct 131 / 2878 = 4.551772063933287%

model file ./aslvid2gloss_v12.3.keras
    result is overfitting, due to on training:
        Total params: 94,185,002 (359.29 MB)
        Trainable params: 31,395,000 (119.76 MB)
        Non-trainable params: 0 (0.00 B)
        Optimizer params: 62,790,002 (239.52 MB)
        Epoch 1/2
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10273s 1s/step - accuracy: 0.5922 - loss: 1.9340
        Epoch 2/2
        7145/7145 ━━━━━━━━━━━━━━━━━━━━ 10214s 1s/step - accuracy: 0.7815 - loss: 1.0867
    and yet testing see ./aslvid2gloss_v12.4.keras above

model file ./aslvid2gloss_v12.keras   1st trainign about 0.02 accuracy
model file ./aslvid2gloss_v12.1.keras 2nd training about 0.2 accuracy
model file ./aslvid2gloss_v12.2.keras 3rd training about 0.5 accuracy

batch train size( TRAIN_BATCH ): 2
TOTAL_GLOSS_UNIQ: 2000

Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩
│ batch_vid (InputLayer)               │ (None, 20, 150, 150, 3)     │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv_lstm2d (ConvLSTM2D)             │ (None, 20, 148, 148, 4)     │           1,024 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling3d (MaxPooling3D)         │ (None, 20, 74, 74, 4)       │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ time_distributed (TimeDistributed)   │ (None, 20, 74, 74, 4)       │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv_lstm2d_1 (ConvLSTM2D)           │ (None, 20, 72, 72, 8)       │           3,488 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling3d_1 (MaxPooling3D)       │ (None, 20, 36, 36, 8)       │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ time_distributed_1 (TimeDistributed) │ (None, 20, 36, 36, 8)       │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv_lstm2d_2 (ConvLSTM2D)           │ (None, 20, 34, 34, 14)      │          11,144 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling3d_2 (MaxPooling3D)       │ (None, 20, 17, 17, 14)      │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ time_distributed_2 (TimeDistributed) │ (None, 20, 17, 17, 14)      │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ conv_lstm2d_3 (ConvLSTM2D)           │ (None, 20, 15, 15, 16)      │          17,344 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ max_pooling3d_3 (MaxPooling3D)       │ (None, 20, 7, 7, 16)        │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ flat_1 (Flatten)                     │ (None, 15680)               │               0 │
├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤
│ batch_class (Dense)                  │ (None, 2000)                │      31,362,000 │
└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘
 Total params: 94,185,002 (359.29 MB)
 Trainable params: 31,395,000 (119.76 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 62,790,002 (239.52 MB)
Epoch 1/2
7144/7144 ━━━━━━━━━━━━━━━━━━━━ 10255s 1s/step - accuracy: 0.0777 - loss: 5.8036
Epoch 2/2
7144/7144 ━━━━━━━━━━━━━━━━━━━━ 10255s 1s/step - accuracy: 0.2023 - loss: 4.2352
input size: (20, 150, 150, 3) with getdata() already in [0.0, 1.0] float32
optimizer: Adam(learning_rate=0.001),
loss: sparse_categorical_crossentropy,
metrics: ['accuracy']
epoch: 2
steps_per_epoch: TOTAL_TRAIN_FILE//TRAIN_BATCH

20            150            150            3
20            148            148            4         <-- (1,3,3) 4    <--- (1,1,1) CNN_LSTM
20            74             74             4         <-- (1,2,2)      <--- (1,2,2) mp3d
20            74             74             4         <-- time distributed dropout

20            72             72             8         <-- (1,3,3) 8    <--- (1,1,1) CNN
20            36             36             8         <-- (1,2,2)      <--- (1,2,2) mp
20            36             36             8         <-- time distributed dropout

20            34             34             14        <-- (1,3,3) 14   <--- (1,1,1) CNN
20            17             17             14        <-- (1,2,2)      <--- (1,2,2) mp
20            17             17             14        <-- time distributed dropout

20            15             15             16        <-- (1,3,3) 14   <--- (1,1,1) CNN
20            7              7              16        <-- (1,2,2)      <--- (1,2,2) mp

1568                                                  <-- flatten ie. 20*7*7*16= 1568

2000                                                  <-- 2000 ANN dense

data_in= Input(
    shape=(QUANTITY_FRAME, IMG_SIZE, IMG_SIZE, 3),
    dtype=float32,
    name='batch_vid'
)



x= ConvLSTM2D(
    filters=4,
    kernel_size=(3,3),
    activation='tanh',
    data_format='channels_last',
    recurrent_dropout=0.2,
    return_sequences=True
)(data_in)
x= MaxPooling3D(
    pool_size=(1,2,2),
    padding='valid',
    data_format='channels_last'
)(x)
x= TimeDistributed(Dropout(0.2))(x)
x= ConvLSTM2D(
    filters=8,
    kernel_size=(3,3),
    activation='tanh',
    data_format='channels_last',
    recurrent_dropout=0.2,
    return_sequences=True
)(x)
x= MaxPooling3D(
    pool_size=(1,2,2),
    padding='valid',
    data_format='channels_last'
)(x)
x= TimeDistributed(Dropout(0.2))(x)
x= ConvLSTM2D(
    filters=14,
    kernel_size=(3,3),
    activation='tanh',
    data_format='channels_last',
    recurrent_dropout=0.2,
    return_sequences=True
)(x)
x= MaxPooling3D(
    pool_size=(1,2,2),
    padding='valid',
    data_format='channels_last'
)(x)
x= TimeDistributed(Dropout(0.2))(x)
x= ConvLSTM2D(
    filters=16,
    kernel_size=(3,3),
    activation='tanh',
    data_format='channels_last',
    recurrent_dropout=0.2,
    return_sequences=True
)(x)
x= MaxPooling3D(
    pool_size=(1,2,2),
    padding='valid',
    data_format='channels_last'
)(x)


x= Flatten(
    name='flat_1'
)(x)
data_out= Dense(
    units=TOTAL_GLOSS_UNIQ,
    activation=softmax,
    name='batch_class'
)(x)








testing ./aslvid2gloss_v12.4.keras: src_asl2gloss/checks/test_asl_vid2gloss_model.py
_______________________________________________________
from os.path import exists
from keras.src.saving import load_model
from numpy import argmax, float32

from ..lmark_constant import IMG_SIZE, PROJ_ROOT, QUANTITY_FRAME, WLASL_VID_DIR, wlasl_READY


from ..lmark_essential_draw import getSkeletonFrames


def test(modelFile: str) -> None:
    if exists(modelFile):
        loadedModel= load_model(modelFile)
        correct: int= 0
        print(f"testing over {len(wlasl_READY['test'])} files, processing...")
        for cur, i in zip(range(len(wlasl_READY['test'])), wlasl_READY['test']):
            print(f"current in progress idx {cur}")
            out: list= loadedModel.predict(getSkeletonFrames(
                f"{WLASL_VID_DIR}{i['video_id']}.mp4"
            ).reshape((1, QUANTITY_FRAME, IMG_SIZE, IMG_SIZE, 3)).astype(float32)/255.0)
            out= out[0]
            if int(argmax(out, axis=-1))==int(i['gloss_id']):
                correct +=1
                print(f"correct( should be {wlasl_READY['label_id2gloss'][i['gloss_id']]} ) calculated be {wlasl_READY['label_id2gloss'][argmax(out, axis=-1)]} {out[argmax(out, axis=-1)]*100}%")
            else:
                print(f"INcorrect( should be {wlasl_READY['label_id2gloss'][i['gloss_id']]} ) calculated be {wlasl_READY['label_id2gloss'][argmax(out, axis=-1)]} {out[argmax(out, axis=-1)]*100}% ________ {i['video_id']}")
        print(f"correct {correct} / {len(wlasl_READY['test'])} = {correct/float(len(wlasl_READY['test']))*100}%")
    else:
        print(f"model file: {modelFile} does not exist")


if __name__=="__main__":
    test(f"{PROJ_ROOT}model/aslvid2gloss_v12.4.keras")

